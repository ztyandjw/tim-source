#Eureka 集群同步1


####1.服务端自身操作完成，开始日志信息同步集群节点

> 移除自身节点

>  PeerAwareInstanceRegistryImpl#replicateToPeers


```bash
private void replicateToPeers(Action action, String appName, String id,InstanceInfo info
                              InstanceStatus newStatus, boolean isReplication) {
    Stopwatch tracer = action.getTimer().start();
    try {
        if (isReplication) {
            numberOfReplicationsLastMin.increment();
        }
        if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) {
            return;
        }
        for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) {
            // 假设是自己，continue
            if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) {
                continue;
            }
            //**注释1**
            replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);
        }
    } finally {
        tracer.stop();
    }
}
```

> 区分不同action，对应不同操作

> PeerAwareInstanceRegistryImpl#replicateInstanceActionsToPeers

```bash

private void replicateInstanceActionsToPeers(Action action, String appName,
                                                 String id, InstanceInfo info, InstanceStatus newStatus,
                                                 PeerEurekaNode node) {
    try {
        InstanceInfo infoFromRegistry = null;
        CurrentRequestVersion.set(Version.V2);
        switch (action) {
            case Cancel:
                node.cancel(appName, id);
                break;
            case Heartbeat:
                InstanceStatus overriddenStatus = overriddenInstanceStatusMap.get(id);
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false);
                break;
            case Register:
                //**注释1**
                node.register(info);
                break;
            case StatusUpdate:
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.statusUpdate(appName, id, newStatus, infoFromRegistry);
                break;
            case DeleteStatusOverride:
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.deleteStatusOverride(appName, id, infoFromRegistry);
                break;
        }
    } catch (Throwable t) {
        logger.error("Cannot replicate information to {} for action {}", node.getServiceUrl(), action.name(), t);
    }
}

```
> 以注册为例子
> PeerEurekaNode#register


```bash

public void register(final InstanceInfo info) throws Exception {
    long expiryTime = System.currentTimeMillis() + getLeaseRenewalOf(info);
    //private final TaskDispatcher<String, ReplicationTask> batchingDispatcher;
    batchingDispatcher.process(
        taskId("register", info),
        new InstanceReplicationTask(targetHost, Action.Register, info, null, true) {
            public EurekaHttpResponse<Void> execute() {
                return replicationClient.register(info);
            }
        },
        expiryTime
    );
}
```

> batchingDispatcher分发器

> batchingDispatcher初始化于PeerEurekaNode构造方法

    private final TaskDispatcher<String, ReplicationTask> batchingDispatcher;

```bash
this.batchingDispatcher = TaskDispatchers.createBatchingTaskDispatcher(
                batcherName,
                config.getMaxElementsInPeerReplicationPool(),
                batchSize,
                config.getMaxThreadsForPeerReplication(),
                maxBatchingDelayMs,
                serverUnavailableSleepTimeMs,
                retrySleepTimeMs,
                taskProcessor
        );
```

> batchingDispatcher接口 com.netflix.eureka.util.batcher.TaskDispatcher

```bash
public interface TaskDispatcher<ID, T> {

    void process(ID id, T task, long expiryTime);

    void shutdown();
}
```


>  工厂方法  TaskDispachers#createBatchingTaskDispatcher

> 创建任务分发器，关联任务执行器TaskExecutors 关联任务接收执行器AcceptorExecutor

```bash
public static <ID, T> TaskDispatcher<ID, T> createBatchingTaskDispatcher(String id,
                                                                             int maxBufferSize,
                                                                             int workloadSize,
                                                                             int workerCount,
                                                                             long maxBatchingDelay,
                                                                             long congestionRetryDelayMs,
                                                                             long networkFailureRetryMs,
                                                                             TaskProcessor<T> taskProcessor) {
        final AcceptorExecutor<ID, T> acceptorExecutor = new AcceptorExecutor<>(
                id, maxBufferSize, workloadSize, maxBatchingDelay, congestionRetryDelayMs, networkFailureRetryMs
        );
        final TaskExecutors<ID, T> taskExecutor = TaskExecutors.batchExecutors(id, workerCount, taskProcessor, acceptorExecutor);
        return new TaskDispatcher<ID, T>() {
            @Override
            public void process(ID id, T task, long expiryTime) {
                acceptorExecutor.process(id, task, expiryTime);
            }

            @Override
            public void shutdown() {
                acceptorExecutor.shutdown();
                taskExecutor.shutdown();
            }
        };
    }
```

> TaskExecutors任务执行器

> 创建始于TaskDispachers#createBatchingTaskDispatcher

    final TaskExecutors<ID, T> taskExecutor = TaskExecutors.batchExecutors(id, workerCount, taskProcessor, acceptorExecutor);

> 创建方法 TaskExecutors#batchExecutors

```bash
static <ID, T> TaskExecutors<ID, T> batchExecutors(final String name,
                                                       int workerCount,
                                                       final TaskProcessor<T> processor,
                                                       //acceptorExcecutor用来给执行线程reprocess失败任务
                                                       final AcceptorExecutor<ID, T> acceptorExecutor) {
        final AtomicBoolean isShutdown = new AtomicBoolean();
        final TaskExecutorMetrics metrics = new TaskExecutorMetrics(name);
        return new TaskExecutors<>(new WorkerRunnableFactory<ID, T>() {
            @Override
            public WorkerRunnable<ID, T> create(int idx) {
                return new BatchWorkerRunnable<>("TaskBatchingWorker-" +name + '-' + idx, isShutdown, metrics, processor, acceptorExecutor);
            }
        }, workerCount, isShutdown);
    }
```

> 构造函数

```bash

TaskExecutors(WorkerRunnableFactory<ID, T> workerRunnableFactory, int workerCount, AtomicBoolean isShutdown) {
        this.isShutdown = isShutdown;
        this.workerThreads = new ArrayList<>();

        ThreadGroup threadGroup = new ThreadGroup("eurekaTaskExecutors");
        for (int i = 0; i < workerCount; i++) {
            WorkerRunnable<ID, T> runnable = workerRunnableFactory.create(i);
            Thread workerThread = new Thread(threadGroup, runnable, runnable.getWorkerName());
            workerThreads.add(workerThread);
            workerThread.setDaemon(true);
            workerThread.start();
        }
    }
```


-------------
####2.任务分发器入口

> 任务分发器接收任务，任务为客户端发送给服务端的新任务，服务端处理完毕，开始同步集群内部节点

> AcceptorExecutor#process

```bash
void process(ID id, T task, long expiryTime) {
    //private final BlockingQueue<TaskHolder<ID, T>> acceptorQueue = new LinkedBlockingQueue<>();
    //队列tail正常放入
    acceptorQueue.add(new TaskHolder<ID, T>(id, task, expiryTime));
    //volatile long acceptedTasks;
    acceptedTasks++;
}
```
> acceptorQueue 是单端阻塞队列， 放入TaskHolder任务

    private final BlockingQueue<TaskHolder<ID, T>> acceptorQueue = new LinkedBlockingQueue<>();


> TaskHolder<ID, T> 是task任务的容器

```bash
class TaskHolder<ID, T> {
    private final ID id;
    private final T task;
    private final long expiryTime;
    private final long submitTimestamp;

    TaskHolder(ID id, T task, long expiryTime) {
        this.id = id;
        this.expiryTime = expiryTime;
        this.task = task;
        this.submitTimestamp = System.currentTimeMillis();
    }
```


####3.任务接收执行器工作线程 AcceptorExecutor$AcceptorRunner 移动队列到pendingQueue

关键数据结构  n个队列，1个map

    private final BlockingQueue<TaskHolder<ID, T>> acceptorQueue = new LinkedBlockingQueue<>();
    private final BlockingDeque<TaskHolder<ID, T>> reprocessQueue = new LinkedBlockingDeque<>();
    private final Deque<ID> processingOrder = new LinkedList<>();
    private final Map<ID, TaskHolder<ID, T>> pendingTasks = new HashMap<>();

> 创建于AcceptorExecutor构造方法(AcceptorExecutor创建于taskDispacher工厂方法)

    this.acceptorThread = new Thread(threadGroup, new AcceptorRunner(), "TaskAcceptor-" + id);
    this.acceptorThread.setDaemon(true);
    this.acceptorThread.start();


> run方法 这只有1个线程，对应一个PeerEurekaNode

```bash
@Override
public void run() {
    long scheduleTime = 0;
    while (!isShutdown.get()) {
        try {
            drainInputQueues();
            //input的两个queue都已经转移，并且pendingtasks有任务
            int totalItems = processingOrder.size();

            long now = System.currentTimeMillis();
            //第一次一定小于now 因为是0啊
            if (scheduleTime < now) {
                //this.trafficShaper = new TrafficShaper(congestionRetryDelayMs, networkFailureRetryMs);
                //计划执行时间依赖于上一次
                scheduleTime = now + trafficShaper.transmissionDelay();
            }
            //计划执行时间早于现在
            if (scheduleTime <= now) {
                //将pendingOrder里的任务移到batchWorkingQueue中
                assignBatchWork();
                assignSingleItemWork();
            }

            // If no worker is requesting data or there is a delay injected by the traffic shaper,
            // sleep for some time to avoid tight loop.
            if (totalItems == processingOrder.size()) {
                Thread.sleep(10);
            }
        } catch (InterruptedException ex) {
            // Ignore
        } catch (Throwable e) {
            // Safe-guard, so we never exit this loop in an uncontrolled way.
            logger.warn("Discovery AcceptorThread error", e);
        }
    }
}
```

> AcceptorExecutor#drainInputQueues
> 只要接收队列 重试队列 有一个不为空，或者pendingTasks为空 就会一直循环，假设所有都为空，休息10ms
> 为什么不直接thread.sleep呢？ 因为怕浪费这10ms。。。

```bash
private void drainInputQueues() throws InterruptedException {
    do {

        drainReprocessQueue();
        drainAcceptorQueue();
        //private final AtomicBoolean isShutdown = new AtomicBoolean(false);
        if (!isShutdown.get()) {
            // If all queues are empty, block for a while on the acceptor queue
            if (reprocessQueue.isEmpty() && acceptorQueue.isEmpty() && pendingTasks.isEmpty()) {
                TaskHolder<ID, T> taskHolder = acceptorQueue.poll(10, TimeUnit.MILLISECONDS);
                if (taskHolder != null) {
                    appendTaskHolder(taskHolder);
                }
            }
        }
        //private final BlockingDeque<TaskHolder<ID, T>> reprocessQueue = new LinkedBlockingDeque<>();
    } while (!reprocessQueue.isEmpty() || !acceptorQueue.isEmpty() || pendingTasks.isEmpty());
}
```
> > 将acceptorQueue中的TaskHolder移动到processOrder中

    private void appendTaskHolder(TaskHolder<ID, T> taskHolder) {
            //假设缓冲区满了，移除一个队首的！
            if (isFull()) {
                pendingTasks.remove(processingOrder.poll());
                queueOverflows++;
            }
            //put如果已经存在，会返回存在的值，如果为空，说明不存在
            TaskHolder<ID, T> previousTask = pendingTasks.put(taskHolder.getId(), taskHolder);
            if (previousTask == null) {
                processingOrder.add(taskHolder.getId());
            } else {
                overriddenTasks++;
            }
        }


> > 耗尽reprocessQueue
> > AcceptorExecutor#drainReprocessQueue

    private void drainReprocessQueue() {
            long now = System.currentTimeMillis();
            //pendingTasks数量大于等于maxBufferSize
            while (!reprocessQueue.isEmpty() && !isFull()) {
                TaskHolder<ID, T> taskHolder = reprocessQueue.pollLast();
                ID id = taskHolder.getId();
                //过期了，不要了这个task
                if (taskHolder.getExpiryTime() <= now) {
                    expiredTasks++;
                //任务id相同覆盖
                } else if (pendingTasks.containsKey(id)) {
                    overriddenTasks++;
                } else {
                    //map存入，这个map作用是1、让order只存id，2、覆盖相同id的任务
                    pendingTasks.put(id, taskHolder);
                    //order放到队首
                    processingOrder.addFirst(id);
                }
            }
            //如果pendingOrder满了，reprocessQueue东西不要了
            if (isFull()) {
                queueOverflows += reprocessQueue.size();
                reprocessQueue.clear();
            }
        }




> > AcceptorExecutor#drainAcceptorQueue
> > 耗尽acceptorqueue中的task

```bash
private void drainAcceptorQueue() {
    while (!acceptorQueue.isEmpty()) {
    appendTaskHolder(acceptorQueue.poll());
    }
}
```

####4.任务接收执行器工作线程 AcceptorExecutor$AcceptorRunner 将pendingOrder移交到真正的执行队列

batchWorkQueue

    private final BlockingQueue<List<TaskHolder<ID, T>>> batchWorkQueue = new LinkedBlockingQueue<>();

runnable run方法
```bash
@Override
public void run() {
    long scheduleTime = 0;
    while (!isShutdown.get()) {
        try {
            drainInputQueues();
            //input的两个queue都已经转移，并且pendingtasks有任务
            int totalItems = processingOrder.size();
            long now = System.currentTimeMillis();
            //第一次一定小于now 因为是0啊
            if (scheduleTime < now) {
                //this.trafficShaper = new TrafficShaper(congestionRetryDelayMs, networkFailureRetryMs);
                //计划执行时间依赖于上一次
                scheduleTime = now + trafficShaper.transmissionDelay();
            }
            //计划执行时间早于现在，说明可以执行了啊！，如果大于现在，等会执行啊
            if (scheduleTime <= now) {
                //将pendingOrder里的任务移到batchWorkingQueue中
                assignBatchWork();
                assignSingleItemWork();
            }

            // If no worker is requesting data or there is a delay injected by the traffic shaper,
            // sleep for some time to avoid tight loop.
            if (totalItems == processingOrder.size()) {
                Thread.sleep(10);
            }
        } catch (InterruptedException ex) {
            // Ignore
        } catch (Throwable e) {
            // Safe-guard, so we never exit this loop in an uncontrolled way.
            logger.warn("Discovery AcceptorThread error", e);
        }
    }
}
```

> TrafficShaper#transmissionDelay
流量整形，根据上一次发生的错误，计算delay的时间

```bash
long transmissionDelay() {
        //lastCongestionError上一次发生拥挤错误的时间
        //lastNetworkFailure上一次发生网络错误的时间
        if (lastCongestionError == -1 && lastNetworkFailure == -1) {
            return 0;
        }
        long now = System.currentTimeMillis();
        if (lastCongestionError != -1) {
            //上一次出错到现在的时间间隔
            long congestionDelay = now - lastCongestionError;
            if (congestionDelay >= 0 && congestionDelay < congestionRetryDelayMs) {
                return congestionRetryDelayMs - congestionDelay;
            }
            //如果拥挤延迟执行已经比重试大了，说明可以立即执行，返回0
            lastCongestionError = -1;
        }
        //同理拥挤，这里理论上不可能都为-1啊
        else if (lastNetworkFailure != -1) {
            long failureDelay = now - lastNetworkFailure;
            if (failureDelay >= 0 && failureDelay < networkFailureRetryMs) {
                return networkFailureRetryMs - failureDelay;
            }
            lastNetworkFailure = -1;
        }
        return 0;
    }
```

> AccetporExcecutor#assignBatchWork

> 终于，将processingOrder放到执行队列去了

```bash
void assignBatchWork() {
    //是否可以执行batch
    if (hasEnoughTasksForNextBatch()) {
        //private final Semaphore batchWorkRequests = new Semaphore(0);
        //为啥0可以accquire（1）呢？？？ BatchWorkerRunnable#run方法见分晓
        if (batchWorkRequests.tryAcquire(1)) {
            long now = System.currentTimeMillis();
            //一次执行的最大数量也有限制
            int len = Math.min(maxBatchingSize, processingOrder.size());
            List<TaskHolder<ID, T>> holders = new ArrayList<>(len);
            while (holders.size() < len && !processingOrder.isEmpty()) {
                ID id = processingOrder.poll();
                TaskHolder<ID, T> holder = pendingTasks.remove(id);
                if (holder.getExpiryTime() > now) {
                    holders.add(holder);
                } else {
                    expiredTasks++;
                }
            }
            //假设一个任务都没有... 信号量释放！可能都过期了？
            if (holders.isEmpty()) {
                batchWorkRequests.release();
            } else {
                batchSizeMetric.record(holders.size(), TimeUnit.MILLISECONDS);
                //private final BlockingQueue<List<TaskHolder<ID, T>>> batchWorkQueue = new LinkedBlockingQueue<>();
                //这个队列里面的元素是List
                //但是为什么没有release
                batchWorkQueue.add(holders);
            }
        }
    }
}
```


> > AccetporExcecutor#hasEnoughTasksForNextBatch

> > 是否可以执行下一次batch操作,1、为空，执行啥子？ 2、超过缓冲上限，立刻给你执行啊，3、如果没有到上限，peek出一个taskHolder，通过当前时间-submit时间，计算出于maxBatchingDelay的相减大小！

```bash
private boolean hasEnoughTasksForNextBatch() {
    //processingOrder为空，肯定不能执行啦
    if (processingOrder.isEmpty()) {
        return false;
    }
    //满了， 肯定给你执行啦
    if (pendingTasks.size() >= maxBufferSize) {
        return true;
    }
    //用peek，不会从队列中移出来
    TaskHolder<ID, T> nextHolder = pendingTasks.get(processingOrder.peek());
    //当前时间-taskHolder生成时间，如果小于maxBatchingDelay， 说明还不需要执行batch
    long delay = System.currentTimeMillis() - nextHolder.getSubmitTimestamp();
    return delay >= maxBatchingDelay;
}
```


####5.任务执行器工作线程 TaskExecutors$BatchWorkerRunnable

构造函数

    BatchWorkerRunnable(String workerName,
                            AtomicBoolean isShutdown,
                            TaskExecutorMetrics metrics,
                            //任务执行器，用来执行任务
                            TaskProcessor<T> processor,
                            //任务接收执行器，用来reprocess失败任务
                            AcceptorExecutor<ID, T> acceptorExecutor) {
            super(workerName, isShutdown, metrics, processor, acceptorExecutor);
        }

通过工厂接口生成

    interface WorkerRunnableFactory<ID, T> {
        WorkerRunnable<ID, T> create(int idx);
    }

通过匿名内部类传入TaskExecutors的构造函数

    return new TaskExecutors<>(new WorkerRunnableFactory<ID, T>() {
        @Override
        public WorkerRunnable<ID, T> create(int idx) {
            return new BatchWorkerRunnable<>("TaskBatchingWorker-" +name + '-' + idx, isShutdown, metrics, processor, acceptorExecutor);
        }

    }, workerCount, isShutdown);

TaskExecutors构造函数

    TaskExecutors(WorkerRunnableFactory<ID, T> workerRunnableFactory, int workerCount, AtomicBoolean isShutdown) {
        this.isShutdown = isShutdown;
        this.workerThreads = new ArrayList<>();

        ThreadGroup threadGroup = new ThreadGroup("eurekaTaskExecutors");
        for (int i = 0; i < workerCount; i++) {
            WorkerRunnable<ID, T> runnable = workerRunnableFactory.create(i);
            Thread workerThread = new Thread(threadGroup, runnable, runnable.getWorkerName());
            workerThreads.add(workerThread);
            workerThread.setDaemon(true);
            workerThread.start();
        }
    }


####5.任务执行器工作线程 run方法

taskProcessor执行器执行结果枚举

    enum ProcessingResult {
            Success, Congestion, TransientError, PermanentError
        }

TaskExecutors$BatchWorkerRunnable#run

```bash
@Override
public void run() {
    try {
        while (!isShutdown.get()) {
            //获取batchingQueue中的
            List<TaskHolder<ID, T>> holders = getWork();
            metrics.registerExpiryTimes(holders);
            List<T> tasks = getTasksOf(holders);
            ProcessingResult result = processor.process(tasks);
            switch (result) {
                case Success:
                    break;
                case Congestion:
                case TransientError:
                    acceptorExecutor.reprocess(holders, result);
                    break;
                case PermanentError:
                    logger.warn("Discarding {} tasks of {} due to permanent error", holders.size(), workerName);
            }
            metrics.registerTaskResult(result, tasks.size());
        }
    } catch (InterruptedException e) {
        // Ignore
    } catch (Throwable e) {
        // Safe-guard, so we never exit this loop in an uncontrolled way.
        logger.warn("Discovery WorkerThread error", e);
    }
}
```

> TaskExecutors#getWork

> requestWorkItems信号量release， 返回batchWorkQueue。由于启动了20个工作线程，所以可以允许放入batch队列20次

> 如果workQueue中啥都没有， 就一直循环吧

> 当本次batch执行完毕，会再一次进入getWork方法，将信号量release放开1

```bash
private List<TaskHolder<ID, T>> getWork() throws InterruptedException {
    BlockingQueue<List<TaskHolder<ID, T>>> workQueue = acceptorExecutor.requestWorkItems();
    List<TaskHolder<ID, T>> result;
    do {
        result = workQueue.poll(1, TimeUnit.SECONDS);
    } while (!isShutdown.get() && result == null);
    return (result == null) ? new ArrayList<>() : result;
}
```

> TaskExecutors#getTasksOf

> 换一下容器，转为List<Task>

```bash
private List<T> getTasksOf(List<TaskHolder<ID, T>> holders) {
    List<T> tasks = new ArrayList<>(holders.size());
    for (TaskHolder<ID, T> holder : holders) {
        tasks.add(holder.getTask());
    }
    return tasks;
}
```

> ReplicationTaskProcessor#process

```bash

@Override
public ProcessingResult process(List<ReplicationTask> tasks) {
    //注解3
    ReplicationList list = createReplicationListOf(tasks);
    try {
        EurekaHttpResponse<ReplicationListResponse> response = replicationClient.submitBatchUpdates(list);
        int statusCode = response.getStatusCode();
        //return statusCode >= 200 && statusCode < 300;

        if (!isSuccess(statusCode)) {
            if (statusCode == 503) {
                logger.warn("Server busy (503) HTTP status code received from the peer {}; rescheduling tasks after delay", peerId);
                return ProcessingResult.Congestion;
            } else {
                // Unexpected error returned from the server. This should ideally never happen.
                logger.error("Batch update failure with HTTP status code {}; discarding {} replication tasks", statusCode, tasks.size());
                return ProcessingResult.PermanentError;
            }
        } else {
            handleBatchResponse(tasks, response.getEntity().getResponseList());
        }
    } catch (Throwable e) {
        if (maybeReadTimeOut(e)) {
            logger.error("It seems to be a socket read timeout exception, it will retry later. if it continues to happen and some eureka node occupied all the cpu time, you should set property 'eureka.server.peer-node-read-timeout-ms' to a bigger value", e);
            return ProcessingResult.Congestion;
        } else if (isNetworkConnectException(e)) {
            logNetworkErrorSample(null, e);
            return ProcessingResult.TransientError;
        } else {
            logger.error("Not re-trying this exception because it does not seem to be a network exception", e);
            return ProcessingResult.PermanentError;
        }
    }
    return ProcessingResult.Success;
}

```

> > ReplicationTaskProcessor#maybeReadTimeOut

> > 首先需要是ioexception，然后查找关键字timeout

> > 循环查找cause

    private static final Pattern READ_TIME_OUT_PATTERN = Pattern.compile(".*read.*time.*out.*");

```bash
private static boolean maybeReadTimeOut(Throwable e) {
    do {
        if (IOException.class.isInstance(e)) {
            String message = e.getMessage().toLowerCase();
            Matcher matcher = READ_TIME_OUT_PATTERN.matcher(message);
            if(matcher.find()) {
                return true;
            }
        }
        e = e.getCause();
    } while (e != null);
    return false;
}
```


> > ReplicationTaskProcessor#isNetworkConnectException


```bash
do {
    if (IOException.class.isInstance(e)) {
        return true;
    }
e = e.getCause();
} while (e != null);
```

> > ReplicationTaskProcessor#createReplicationInstanceOf
通过builder生成器，生成replicationInstance

```bash
private static ReplicationInstance createReplicationInstanceOf(InstanceReplicationTask task) {
    ReplicationInstanceBuilder instanceBuilder = ReplicationInstanceBuilder.replicationInstanceBuilder;
    instanceBuilder.withAppName(task.getAppName());
    instanceBuilder.withId(task.getId());
    InstanceInfo instanceInfo = task.getInstanceInfo();
    if (instanceInfo != null) {
        String overriddenStatus = task.getOverriddenStatus() == null ? null : task.getOverriddenStatus().name();
        instanceBuilder.withOverriddenStatus(overriddenStatus);
        instanceBuilder.withLastDirtyTimestamp(instanceInfo.getLastDirtyTimestamp());
        if (task.shouldReplicateInstanceInfo()) {
            instanceBuilder.withInstanceInfo(instanceInfo);
        }
        String instanceStatus = instanceInfo.getStatus() == null ? null : instanceInfo.getStatus().name();
        instanceBuilder.withStatus(instanceStatus);
    }
    instanceBuilder.withAction(task.getAction());
    return instanceBuilder.build();
}
```

> > AcceptorExecutor.reprocess

> > 假设是拥挤错误或者网络错误， 重试队列，流量整形注册错误

```bash
void reprocess(List<TaskHolder<ID, T>> holders, ProcessingResult processingResult) {
    reprocessQueue.addAll(holders);
    replayedTasks += holders.size();
    trafficShaper.registerFailure(processingResult);
}

```